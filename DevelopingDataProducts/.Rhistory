source("http://www.openintro.org/stat/data/present.R")
present
dim(present)
names(present)
present$boys
present$girls
plot(x = present$year, y = present$girls)
plot(x = present$year, y = present$boys)
plot(x = present$year, y = present$girls, type = "l")
present$boys + present$girls
plot(present$year, present$boys + present$girls, type = "l")
max(present$boys + present$girls)
which.max(present$boys + present$girls)
present$year[22]
present$boys/present$girls
present$boys/(present$boys + present$girls)
plot(present$year, present$boys/(present$boys + present$girls), type = "l")
present$boys > present$girls
plot(present$year, present$boys/present$girls, type = "l")
abs(0-1)
0-1
abs(0-1)
abs(present$boys-present$girls)
which.max(abs(present$boys-present$girls))
present$year[24]
source("http://www.openintro.org/stat/data/cdc.R")
names(cdc)
head(cdc)
head(cdc$gender[cdc$gender="m"])
head(cdc$gender[cdc$gender=="m"])
length(cdc$gender)
length(cdc$gender[cdc$gender=="m"])
summary(cdc$weight)
table(cdc$smoke100)
table(cdc$smoke100)/20000
barplot(table(cdc$smoke100))
summary(cdc$gender)
table(cdc$genhlth)
table(cdc$genhlth)/20000
gender_smokers = table(cdc$gender, cdc$smoke100)
gender_smokers
mosaicplot(gender_smokers)
dim(cdc)
mdata = subset(cdc, cdc$gender == "m")
under23 and smoke <- subset(cdc, cdc$age < 23 & cdc$smoke100 == 1)
under23_and_smoke <- subset(cdc, cdc$age < 23 & cdc$smoke100 == 1)
boxplot(cdc$height)
summary(cdc$height)
boxplot(cdc$height ~
cdc$gender)
bmi = (cdc$weight/cdc$height^2) * 703
boxplot(bmi ~
cdc$genhlth)
boxplot(cdc$weight ~ cdc$wtdesire)
hist(cdc$age)
hist(bmi)
hist(bmi, breaks = 50)
plot(cdc$weigth, cdc$wtwiegth)
plot(cdc$weigth, cdc$wtweigth)
plot(cdc$weigth, cdc$wtdesire)
plot(cdc$weight, cdc$wtdesire)
load(url("http://www.openintro.org/stat/data/kobe.RData"))
head(kobe)
kobe$basket[1:9]
kobe_streak <- calc_streak(kobe$basket)
barplot(table(kobe_streak))
summary(kobe_streak)
head(table(kobe_streak))
outcomes <- c("heads", "tails")
sim_fair_coin <- sample(outcomes, size = 100, replace = TRUE)
sim_unfair_coin <- sample(outcomes, size = 100, replace = TRUE, prob = c(0.2, 0.8))
table(sim_unfair_coin)
outcomes <- c("H", "M")
sim_basket <- sample(outcomes, size = 1, replace = TRUE)
sim_basket <- sample(outcomes, size = 133, replace = TRUE, prob = c(0.45, 0.55))
basket_streak <- calc_streak(sim_basket)
barplot(table(basket_streak))
load(url("http://bit.ly/dasi_gss_data"))
head(gss)
x <- gss$tvhours[gss$tvhours <> NA]
x <- gss$tvhours[!is.na(gss$tvhours)]
length(x)
x <- gss$fear[!is.na(gss$fear)]
length(x)
head(x)
x <- gss$tvhours[!is.na(gss$tvhours)]
max(x)
median(x)
mean(x)
summary(x)
hist(gss$tvhours)
hist(gss$fear)
plot(gss$fear, gss$tvhours)
plot(gss$tvhours, gss$fear)
plot(gss$fear, gss$news)
plot(gss$race, gss$racdif1)
plot(gss$year, gss$racdif1)
plot(gss$race, gss$racdif4)
plot(gss$race, gss$racdif3)
head(gss$race)
head(gss$racdif1)
x <- gss$race[!is.na(gss$race)]
length(x)
x <- gss$racdif1[!is.na(gss$racdif1)]
length(x)
x <- gss$race[gss$race = "White"]
x <- gss$race[gss$race == "White"]
head(x)
table(x)
x <- gss$race[gss$race == "White" & !is.na(gss$racdif1)]
table(x)
x <- gss$race[gss$race == "Black" & !is.na(gss$racdif1)]
table(x)
x <- gss$race[gss$race == "Other" & !is.na(gss$racdif1)]
table(x)
page(gss)
page("gss")
x <- subset(gss, !is.na(gss$racdif1), select = c(race, racdif1))
head(x)
table(x)
head(y,n=40)
head(x,n=40)
head(x,n=40, addrownums = FALSE)
head(x,n=40, addrownums = TRUE)
head(x,n=40, addrownums = FALSE)
pnorm(rnorm(200, mean = 0.9, sd = 0.0212), mean = 0.9, sd = 0.0212, lower.tail = FALSE)
pnorm(2.36, mean = 0.9, sd = 0.0212, lower.tail = FALSE)
pnorm(0.36, mean = 0.9, sd = 0.0212, lower.tail = FALSE)
pnorm(c(0.36), mean = 0.9, sd = 0.0212, lower.tail = FALSE)
pnorm(c(2.36), mean = 0.9, sd = 0.0212, lower.tail = FALSE)
pnorm(c(2.36), mean = 0.90, sd = 0.0212, lower.tail = FALSE)
pnorm(c(2.36), mean = 0.90, sd = 0.0212)
(1.96*1.96)*0.5*0.5/(0.03*0.03)
load(url("http://bit.ly/dasi_gss_data"))
states = read.csv("http://bit.ly/dasi_states")
pov_slr = lm(poverty ~ female_house, data = states)
pov_slr
summary(pov_slr)
pov_slr = lm(poverty ~ female_house + white, data = states)
summary(pov_slr)
132.57/480.25
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
library(rCharts)
install.packages("rCharts")
library(rCharts)
install.packages("rCharts")
install.packages("rCharts")
install.packages("shiny")
load(cars)
library(cars)
dataset(cars)
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1)
cars.1
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1, xlim = c(0, 25))
d <- seq(0, 25, length.out = 200)
for(degree in 1:4) {
fm <- lm(dist ~ poly(speed, degree), data = cars)
assign(paste("cars", degree, sep = "."), fm)
lines(d, predict(fm, data.frame(speed = d)), col = degree)
}
anova(cars.1, cars.2, cars.3, cars.4)
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1, xlim = c(0, 25))
fm <- lm(dist ~ speed, data = cars)
lines(fm)
line(fm)
abline(fm)
predict(fm, 30)
predict(fm, data.frame(speed = 30))
predict(fm, data.frame(speed = 24))
data(cars)
points(24, predict(fm, data.frame(speed = 24)), pch=19)
setwd("C:/Felipe Rosário/Github/courses/09_DevelopingDataProducts/shiny2/testApp3")
startApp()
runApp()
library(shiny)
runApp()
setwd("C:/Felipe Rosário/Github/courses/09_DevelopingDataProducts/shiny/testApp")
runApp()
setwd("C:/Felipe Rosário/Github/datasciencecoursera/DevelopingDataProducts")
runApp()
points(24, predict(fm, data.frame(speed = 24)), pch=19)
data(cars)
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1, xlim = c(0, 25))
abline(fm)
predict(fm, data.frame(speed = 24))
points(24, predict(fm, data.frame(speed = 24)), pch=19)
runApp()
runApp()
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
library(shiny)
runApp()
shinyapps::setAccountInfo(name='felipegr', token='86CE4207AD412AEED4A8B4CB077CDFCD', secret='uV4eCk6iXnQDFnyyNUT1pfF8qzXAswRF6Ho9QpY0')
deployApp()
library(shinyapps)
deployApp()
runApp()
deployApp()
ibrary(slidify)
library(slidify)
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library('slidify')
setwd("C:/Felipe Rosário/Github/datasciencecoursera/DevelopingDataProducts")
author('slidify_presentation')
setwd("C:/Felipe Rosário/Github/datasciencecoursera/DevelopingDataProducts/slidify_presentation")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
data(cars)
summary(cars)
length(cars)
lines(cars)
dim(cars)
fm <- lm(dist ~ speed, data = cars)
predict(fm, data.frame(speed = 23))
publish(user = "felipegr", repo = "developingdataproducts_slidify")
warnings()
publish(user = "felipegr", repo = "developingdataproducts_slidify")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
install.packages("caret")
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(ggplot2)
qplot(training$CompressiveStrength)
qplot(CompressiveStrength, data=training)
qplot(CompressiveStrength, count, data=training)
training
head(training)
training$row
qplot(CompressiveStrength, row(training), data=training)
row(training)
diag(row(training))
x <- [1:10]
x <- ([)1:10)
x <- (1:10)
x
nrow(training)
x <- (1:774)
qplot(CompressiveStrength, x, data=training)
qplot(x, CompressiveStrength, data=training)
qplot(x, CompressiveStrength, data=training, colour=Age)
qplot(x, CompressiveStrength, data=training, colour=Cement)
qplot(x, CompressiveStrength, data=training, colour=cut(Cement,g=4))
qplot(x, CompressiveStrength, data=training, colour=cut2(Cement,g=4))
y <- cut2(training$Cement, g=4)
library(Hmisc)
install.packages("Hmisc")
y <- cut2(training$Cement, g=4)
library(Hmisc)
y <- cut2(training$Cement, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
y <- cut2(training$BlastFurnaceSlag, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
y <- cut2(training$FlyAsh, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
y <- cut2(training$Water, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
y <- cut2(training$Superplasticizer, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
y <- cut2(training$CoarseAggregate, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
y <- cut2(training$FineAggregate, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
y <- cut2(training$Age, g=4)
qplot(x, CompressiveStrength, data=training, colour=y)
qplot(Superplasticizer, data=training)
qplot(log(Superplasticizer), data=training)
qplot(abs(log(Superplasticizer)), data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
trainSet <- train[, 58]
trainSet <- training[, 58]
trainSet <- training[, 58:69]
preProc <- preProcess(trainSet,method="pca",pcaComp=7)
trainPC <- predict(preProc, trainSet)
plot(trainPC)
preProc
var(trainPC)
preProc <- preProcess(trainSet,method="pca",pcaComp=9)
trainPC <- predict(preProc, trainSet)
plot(trainPC)
preProc <- preProcess(trainSet,method="pca",pcaComp=7)
trainPC <- predict(preProc, trainSet)
modelFit <- train(training$diagnosis ~ .,method="glm",data=trainPC)
library(caret)
modelFit <- train(training$diagnosis ~ .,method="glm",data=trainPC)
library(e1071)
install.packages("e1071")
library(e1071)
modelFit <- train(training$diagnosis ~ .,method="glm",data=trainPC)
modelFit
testPC <- predict(preProc,testing[, 58:69])
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$diagnosis,predict(modelFit,testing))
modelFit
modelFit$finalModel
modelFit$preProcess
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess="pca",data=training, pcaComp=7)
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess="pca",data=training, pcaComp=9)
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess="pca",data=training, pcaComp=10)
modelFit$preProcess(thresh=90)
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess=preProcess(training, tresh=0.9),data=training)
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess=preProcess(training[, 58:69], tresh=0.9),data=training)
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess="pca",data=training)
modelFit$preProcess
preProcess(training)
preProcess(training[, 58:69])
x <- preProcess(training[, 58:69], tresh=0.9)
x
x$pcaComp
x$data
x
x <- preProcess(training[, 58:69], tresh=0.9, method="pca")
x
x <- preProcess(training[, 58:69], tresh=0.90, method="pca")
x
x <- preProcess(training[, 58:69], method="pca", pcaComp=7)
x
x <- preProcess(training[, 58:69], method="pca", thresh = 0.90)
x
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSet <- training[, c(1,58:69)]
modelFit <- train(diagnosis ~.,data=training, method="glm")
confusionMatrix(testing$diagnosis, modelFit)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
x <- preProcess(training[, 58:69], method="pca", thresh = 0.90)
trainPC <- predict(x,trainSet))
trainPC <- predict(x,trainSet)
trainPC <- predict(x,training)
trainPC <- predict(x,training[, 58:69]))
trainPC <- predict(x,training[, 58:69])
modelFit2 <- train(training$diagnosis ~ .,method="glm",data=trainPC)
testPC <- predict(x,testing[,58:69])
confusionMatrix(testing$diagnosis,predict(modelFit2,testPC))
x <- preProcess(training[, 58:69], method="pca", thresh = 0.80)
trainPC <- predict(x,training[, 58:69])
modelFit2 <- train(training$diagnosis ~ .,method="glm",data=trainPC)
testPC <- predict(x,testing[,58:69])
confusionMatrix(testing$diagnosis,predict(modelFit2,testPC))
modelFit <- train(diagnosis ~.,data=trainSet, method="glm")
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
log(0)
data(concrete)
log(concrete$Superplasticizer) + 1
hist(log(concrete$Superplasticizer) + 1)
hist(log(concrete$Superplasticizer+1))
library(caret)
